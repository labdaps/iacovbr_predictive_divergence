{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DATASET LOADING"
      ],
      "metadata": {
        "id": "M4GU8kJ08EWj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6wqvrbZ73Hq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(PATH)\n",
        "df_raw = pd.DataFrame(dataset)\n",
        "\n",
        "#filter predictors\n",
        "df = df_raw[['X','idade','genero','fc','fr','pa_sist','pa_diast','pam','temp','hb',\n",
        "              'plaquetas','ht','hemacias','hcm','rdw','vcm','leucocitos','neutrofilos',\n",
        "              'linfocitos','basofilos','eosinofilos','monocitos','proteina_c_reativa', \"obito\"]]\n",
        "\n",
        "#filter patients by age and PCR\n",
        "df = df.loc[df['rt_pcr_covid'] == \"Positivo\"]\n",
        "df = df[df[\"idade\"] >= 18]\n",
        "\n",
        "#one hot encoding\n",
        "df[\"genero\"] = np.select([df[\"genero\"] == \"Masc\", df[\"genero\"] == \"Fem\"], [0, 1])\n",
        "df['obito'] = df['obito']. fillna(0)\n",
        "df['obito'] = df['obito'].apply(lambda x: 1 if x != 0 else 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY ANALYSIS"
      ],
      "metadata": {
        "id": "C4Q6Ew7b9g3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df.shape\n",
        "df.head()\n",
        "df.info()\n",
        "\n",
        "df[numeric_features].describe().T\n",
        "\n",
        "for feature in dummy_features:\n",
        "  print(df[feature].value_counts(normalize = True))\n",
        "\n",
        "#boxplots\n",
        "plt.figure(figsize =(30,100))\n",
        "\n",
        "for i, feature in enumerate(numeric_features, 1):\n",
        "  plt.subplot(10,2,i)\n",
        "  sns.boxplot(x=df[feature])\n",
        "  plt.title(f'Boxplot of {feature}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#histograms\n",
        "plt.figure(figsize =(30,100))\n",
        "\n",
        "for i, feature in enumerate(numeric_features, 1):\n",
        "  plt.subplot(10,2,i)\n",
        "  sns.histplot(x=df[feature])\n",
        "  plt.title(f'Histogram of {feature}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fe5N6z9y9i7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "b3n9hSGK-5pK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import missingno as msno\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "#missing values\n",
        "df.isnull().any()\n",
        "msno.matrix(df)\n",
        "\n",
        "df['missing_exame_sangue'] = 0\n",
        "df.loc[(df['missing_exame_sangue'] == '') | (df['hb'].isna()), 'missing_exame_sangue'] = 1\n",
        "df['missing_exame_sangue'].value_counts(normalize=True)\n",
        "\n",
        "\n",
        "#train-test split\n",
        "X_df = df.drop(columns=[\"obito\"])\n",
        "y_df = df[[\"obito\"]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.3, random_state=42, stratify= y_df)\n",
        "\n",
        "X_train[numeric_features].describe().T\n",
        "\n",
        "#missing filter and imputation\n",
        "for column in X_train.columns:\n",
        "  if  X_train[column].isnull().mean() >= 0.9:\n",
        "    X_train = X_train.drop(column, axis=1)\n",
        "    X_test = X_test.drop(column, axis =1)\n",
        "  else:\n",
        "    X_train[column] = X_train[column].fillna(X_train[column].median())\n",
        "    X_test [column] = X_test [column].fillna(X_train[column].median())\n",
        "\n",
        "#correlation filter\n",
        "corr = X_train[numeric_features].corr()\n",
        "for i in range(len(numeric_features)):\n",
        "  for j in range(len(numeric_features)):\n",
        "    if i!=j and corr.iloc[i, j] > 0.9:\n",
        "      X_train = X_train.drop(X_train.columns[i], axis=1)\n",
        "      X_test = X_test.drop(X_train.columns[i], axis=1)\n",
        "\n",
        "#normalization\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(X_train[numeric_features])\n",
        "X_train[numeric_features] = scaler.transform(X_train[numeric_features])\n",
        "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
        "\n",
        "#class balancing\n",
        "oversample = RandomOverSampler(sampling_strategy='minority', random_state =42)\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "ovn-JivW-7Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL TRAINNING"
      ],
      "metadata": {
        "id": "QC6iKRjaAz0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import shap\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "def objective(params):\n",
        "    auc_scores = []\n",
        "\n",
        "    for train_index, val_index in kf.split(X_train):\n",
        "      x_t, x_v = X_train[train_index], X_train[val_index]\n",
        "      y_t, y_v = y_train[train_index], y_train[val_index]\n",
        "\n",
        "      clf.fit(x_t, y_t)\n",
        "      preds = clf.predict_proba(x_v)[:, 1]\n",
        "      auc = roc_auc_score(y_v, preds)\n",
        "      auc_scores.append(auc)\n",
        "\n",
        "    auc = np.mean(auc_scores)\n",
        "    return {'loss': -auc, 'status': STATUS_OK}\n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective,\n",
        "        space=param_space,\n",
        "        algo=tpe.suggest,\n",
        "        max_evals=100,\n",
        "        trials=trials)\n",
        "\n",
        "final_model = clf(**best, use_label_encoder=False, eval_metric='auc')\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "preds = final_model.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, preds)\n",
        "RocCurveDisplay.from_predictions(y_test, preds)\n",
        "\n",
        "preds = [0 if x <0.5 else 1 for x in preds]\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "\n",
        "cf_matrix = confusion_matrix(y_test, preds)\n",
        "cf_percent = cf_matrix.astype('float') / cf_matrix.sum()\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cf_percent, display_labels=final_model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues, ax=ax, values_format=\".2f\")\n",
        "\n",
        "misclassified = []\n",
        "for index in range(len(y_test)):\n",
        "    if int(y_test.iloc[index]) != preds[index]:\n",
        "       misclassified.append(index)\n",
        "\n",
        "explainer = shap.Explainer(final_model)\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"dot\")\n",
        "\n",
        "#TabPFN\n",
        "from tabpfn import TabPFNClassifier\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import shapiq\n",
        "\n",
        "tabpfn_model = TabPFNClassifier()\n",
        "\n",
        "tabpfn_model.fit(X_train, y_train)\n",
        "preds = tabpfn_model.predict_proba(X_test)\n",
        "\n",
        "auc = roc_auc_score(y_test, (preds[:, 1]))\n",
        "RocCurveDisplay.from_predictions(y_test, (preds[:, 1]))\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, preds[:, 1])\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
        "best_threshold = thresholds[f1_scores.argmax()]\n",
        "tab_final_preds = (tab_final_preds[:, 1] > best_threshold).astype(int)\n",
        "\n",
        "tab_accuracy = accuracy_score(y_test, tab_final_preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "\n",
        "cf_matrix = confusion_matrix(y_test, preds)\n",
        "cf_percent = cf_matrix.astype('float') / cf_matrix.sum()\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cf_percent, display_labels=final_model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues, ax=ax, values_format=\".2f\")\n",
        "\n",
        "misclassified = []\n",
        "for index in range(len(y_test)):\n",
        "    if int(y_test.iloc[index]) != preds[index]:\n",
        "       misclassified.append(index)\n",
        "\n",
        "x_explain = X_test.values[200]\n",
        "y_explain = y_test.values[200]\n",
        "\n",
        "explainer = shapiq.Explainer(\n",
        "    model=TabPFNClassifier(device = 'cpu'),\n",
        "    data=X_train_subset.values,\n",
        "    labels=y_train_subset,\n",
        "    index=\"FSII\",\n",
        "    max_order=1,\n",
        ")\n",
        "explainer._imputer.verbose = True\n",
        "fsii = explainer.explain(x_explain, budget=100)\n",
        "display(fsii.dict_values)\n",
        "fsii.plot_force(feature_names=feature_names)"
      ],
      "metadata": {
        "id": "N9m6cJh7A1mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROBABILISTIC PREDICTIONS CORRELATION"
      ],
      "metadata": {
        "id": "sFq6qtMHGgYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "df_long = df.reset_index().rename(columns={'index': 'hospital'})\n",
        "model_cols = ['xgb_preds', 'rf_preds', 'lgb_preds', 'cat_preds', 'tab_preds']\n",
        "long_format = []\n",
        "\n",
        "for _, row in df_long.iterrows():\n",
        "    hospital = row['hospital']\n",
        "    preds_dict = {model: row[model] for model in model_cols}\n",
        "    num_pacientes = len(row[model_cols[0]])\n",
        "\n",
        "    temp_df = pd.DataFrame({\n",
        "        'hospital': [hospital] * num_pacientes,\n",
        "        **{model: preds_dict[model] for model in model_cols}\n",
        "    })\n",
        "\n",
        "    long_format.append(temp_df)\n",
        "\n",
        "df_final = pd.concat(long_format, ignore_index=True)\n",
        "\n",
        "sns.set_style('white')\n",
        "palette = sns.color_palette(\"YlGnBu\", 5)\n",
        "\n",
        "g = sns.pairplot(df_final, hue='Hospital', aspect=1, diag_kind= 'hist', corner=True, palette =palette)\n",
        "\n",
        "for ax in g.axes.flat:\n",
        "    if ax:\n",
        "        ax.set_xlim(-0.02, 1.02)\n",
        "        ax.set_ylim(-0.02, 1.02)\n",
        "\n",
        "vars = df_final.columns[1:]\n",
        "\n",
        "for i in range(len(vars)):\n",
        "    for j in range(i):\n",
        "        x = df_final[vars[j]].values.reshape(-1, 1)\n",
        "        y = df_final[vars[i]].values\n",
        "        model = LinearRegression().fit(x, y)\n",
        "        r2 = r2_score(y, model.predict(x))\n",
        "\n",
        "        ax = g.axes[i, j]\n",
        "        x_plot = x.flatten()\n",
        "        y_pred = model.predict(x)\n",
        "        ax.plot(x_plot, y_pred, color='blue')\n",
        "\n",
        "        ax.set_xlabel(ax.get_xlabel(), fontsize=13.5, labelpad=10)\n",
        "        ax.set_ylabel(ax.get_ylabel(), fontsize=13.5, labelpad=10)\n",
        "\n",
        "        ax.annotate(f\"$R^2$ = {r2:.2f}\",\n",
        "                    xy=(0.03, 0.96), xycoords='axes fraction',\n",
        "                    ha='left', va='top', fontsize=14, color='black',\n",
        "                    bbox=dict(boxstyle='round,pad=0.2', facecolor='white', edgecolor='none', alpha=0.8))\n",
        "\n",
        "\n",
        "g._legend.set_title('Hospital')\n",
        "for text in g._legend.texts:\n",
        "    text.set_fontsize(13)\n",
        "\n",
        "title = g._legend.get_title()\n",
        "title.set_fontsize(14)\n",
        "title.set_fontweight('bold')\n",
        "\n",
        "g._legend.set_bbox_to_anchor((0.8, 0.75))\n",
        "g._legend.set_frame_on(True)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "aBDjfgXhG51d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROFILE GRAPH BY ERROR GROUP"
      ],
      "metadata": {
        "id": "f7_zcSkxHo8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_vectors = pd.DataFrame()\n",
        "\n",
        "for algorithm in algorithms:\n",
        "  X_test_sampled = X_test.loc[list(df_errors[algorithm].dropna())]\n",
        "  mean_vector = X_test_sampled.mean()\n",
        "  mean_vectors[algorithm] = mean_vector\n",
        "\n",
        "flat_misclassified = [item for sublist in misclassified for item in sublist]\n",
        "X_test_not_misclassified = X_test.loc[list(set(X_test.index) - set(flat_misclassified))]\n",
        "\n",
        "mean_vectors[\"Not misclassified\"] = X_test_not_misclassified.mean()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "colors = sns.color_palette(\"YlGnBu\", n_colors=len(legend))\n",
        "\n",
        "for i, (algorithm, mean_vector) in enumerate(mean_vectors.items()):\n",
        "    ax.plot(mean_vector.index, mean_vector.values, linestyle='--', marker= \".\", markersize = 12, label=legend[algorithm], color = colors[i])\n",
        "\n",
        "plt.axhline(y=0, color='grey')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "translated_labels = [x_label.get(label, label) for label in mean_vector.index]\n",
        "ax.set_xticks(range(len(translated_labels)))\n",
        "ax.set_xticklabels(translated_labels, rotation=90)\n",
        "ax.set_xlabel('Variables')\n",
        "ax.set_ylabel('Mean')\n",
        "\n",
        "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fQc5tbIAHr0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STATISTICAL TESTS"
      ],
      "metadata": {
        "id": "tgppQ_uXJnIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "from scipy import stats\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "all_patients = [i for i in range(len(X_test))]\n",
        "\n",
        "for x in all_patients:\n",
        "  for model in models:\n",
        "    if x in misclassified[model]:\n",
        "        matriz[x][models.index(model)] = 1\n",
        "\n",
        "df_errors = pd.DataFrame.from_dict(matriz, orient='index', columns=['Patient', 'XGBoost', 'Random Forest', 'TabPFN', 'LightGBM', 'CatBoost'])\n",
        "target = ['XGBoost', 'Random Forest', 'TabPFN', 'LightGBM', 'CatBoost']\n",
        "error_all_models = []\n",
        "no_error = []\n",
        "\n",
        "for index, row in df_errors.iterrows():\n",
        "    soma = row[target].sum()\n",
        "    if soma == 0:\n",
        "      no_error.append(row[\"Patient\"])\n",
        "    elif soma == 5:\n",
        "      error_all_models.append(row[\"Patient\"])\n",
        "\n",
        "sampled_indexes = no_error + error_all_models\n",
        "X_test_sampled = X_test.loc[sampled_indexes]\n",
        "X_test_sampled['error'] = X_test_sampled.index.map(lambda i: 1 if i in error_all_models else 0)\n",
        "\n",
        "data_1 = X_test_sampled.loc[X_test_sampled['error'] ==1]\n",
        "data_0 = X_test_sampled.loc[X_test_sampled['error'] ==0]\n",
        "\n",
        "#Shapiro-Wilk, normal distribution\n",
        "for feature in X_test_sampled:\n",
        "  s = scipy.stats.shapiro(X_test_sampled[feature])\n",
        "  if s.pvalue < 0.005:\n",
        "    not_normal.append(feature)\n",
        "  else:\n",
        "    normal.append(feature)\n",
        "\n",
        "#Levene, homocedasticity\n",
        "for i, feature in enumerate(X_test_sampled.columns[:-1], 1):\n",
        "  s = stats.levene(data_0[feature], data_1[feature], center= 'mean')\n",
        "  if s.pvalue < 0.005:\n",
        "    diff_var.append(feature)\n",
        "  else:\n",
        "    homocedastic.append(feature)\n",
        "\n",
        "#Paired t-test\n",
        "t_features = set(normal).intersection(homocedastic)\n",
        "for i, feature in enumerate(t_features, 1):\n",
        "  t_stat, p_value = stats.ttest_ind(data_0[feature], data_1[feature])\n",
        "  if p_value < 0.005:\n",
        "    reject.append(feature)\n",
        "\n",
        "#Mann-Whitney U test\n",
        "mw_features = set(X_test_sampled.columns[:-1]).difference(t_features)\n",
        "for i, feature in enumerate(mw_features, 1):\n",
        "  test_stat, p_value = mannwhitneyu(data_0[feature], data_1[feature])\n",
        "  if p_value < 0.005:\n",
        "    reject.append(feature)"
      ],
      "metadata": {
        "id": "WowM2syPJwoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHAP BOXPLOTS"
      ],
      "metadata": {
        "id": "x5BHJ6W7NfnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap_data = pd.DataFrame()\n",
        "for hospital in hospitals:\n",
        "  for algorithm in algorithms:\n",
        "    path = f\"/content/drive/MyDrive/{hospital}/{algorithm}_shap_values{hospital}.csv\"\n",
        "    df = pd.read_csv(path, sep =\";\")\n",
        "    for column in df.columns:\n",
        "      df[column] = pd.to_numeric(df[column], errors='coerce').fillna(0).abs()\n",
        "    shap_data = pd.concat([shap_data, df], ignore_index=True)\n",
        "\n",
        "shap_data = shap_data.drop(\"Unnamed: 0\", axis=1)\n",
        "mean_shap = shap_data.mean().sort_values(ascending=False)\n",
        "\n",
        "top_features = mean_shap.head(10).index\n",
        "shap_top = shap_data[top_features].melt(var_name=\"Feature\", value_name=\"SHAP Value\")\n",
        "\n",
        "reversed_blues = sns.color_palette(\"Blues\", n_colors=10, as_cmap=False)[::-1]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.boxplot(data=shap_top, x=\"Feature\", y=\"SHAP Value\", palette=reversed_blues, showfliers=False)\n",
        "\n",
        "translated_labels = [x_label.get(label, label) for label in  shap_top[\"Feature\"].unique()]\n",
        "\n",
        "ax.set_xticks(range(len(translated_labels)))\n",
        "ax.set_xticklabels(translated_labels, rotation=45, ha=\"right\")\n",
        "plt.xlabel(\"\")\n",
        "plt.ylabel(\"SHAP Value\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9lU53gpjNhKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLUSTER ANALYSIS"
      ],
      "metadata": {
        "id": "iqSh2tntVMc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def calculate_wcss(data):\n",
        "    wcss = []\n",
        "    for n in range(2, 11):\n",
        "        kmeans = KMeans(n_clusters=n, random_state=42)\n",
        "        kmeans.fit(X=data)\n",
        "        wcss.append(kmeans.inertia_)\n",
        "    return wcss\n",
        "\n",
        "def optimal_number_of_clusters(wcss):\n",
        "    x1, y1 = 2, wcss[0]\n",
        "    x2, y2 = 11, wcss[len(wcss)-1]\n",
        "    distances = []\n",
        "    for i in range(len(wcss)):\n",
        "        x0 = i+2\n",
        "        y0 = wcss[i]\n",
        "        numerator = abs((y2-y1)*x0 - (x2-x1)*y0 + x2*y1 - y2*x1)\n",
        "        denominator = sqrt((y2 - y1)**2 + (x2 - x1)**2)\n",
        "        distances.append(numerator/denominator)\n",
        "    return distances.index(max(distances)) + 2\n",
        "\n",
        "sum_of_squares = calculate_wcss(X_train)\n",
        "n = optimal_number_of_clusters(sum_of_squares)\n",
        "\n",
        "plt.axvline(n)\n",
        "plt.plot(range(2,11), sum_of_squares)\n",
        "plt.xlabel(\"Number of clusters\")\n",
        "plt.ylabel(\"WCSS\")\n",
        "plt.show()\n",
        "\n",
        "kmeans = KMeans(n_clusters=n, random_state=43)\n",
        "clusters = kmeans.fit_predict(X_train)\n",
        "\n",
        "translated_features = [x_label[feat] for feat in top_features]\n",
        "\n",
        "X_train_sampled = X_train[top_features]\n",
        "X_train_sampled['cluster'] = clusters\n",
        "\n",
        "mean_vectors = X_train_sampled.groupby('cluster').mean()\n",
        "mean_vectors.rename(columns=x_label, inplace=True)\n",
        "\n",
        "n = mean_vectors.shape[0]\n",
        "fig, axes = plt.subplots(nrows=1, ncols=n, figsize=(24, 12), subplot_kw={'projection': 'polar'})\n",
        "\n",
        "features = mean_vectors.columns\n",
        "num_features = len(features)\n",
        "angles = np.linspace(0, 2 * np.pi, num_features, endpoint=False).tolist()\n",
        "\n",
        "for i, (cluster_id, mean_vector) in enumerate(mean_vectors.iterrows()):\n",
        "    ax = axes[i]\n",
        "    values = mean_vector.values.tolist()\n",
        "    angles_closed = angles + angles[:1]\n",
        "    values_closed = values + values[:1]\n",
        "\n",
        "    ax.plot(angles_closed, values_closed, label=f\"{cluster_names[cluster_id]}\", linewidth=2)\n",
        "    ax.fill(angles_closed, values_closed, alpha=0.25)\n",
        "\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xticks(angles_closed)\n",
        "\n",
        "    feature_labels = features.tolist() + [features[0]]\n",
        "    ax.set_xticklabels(feature_labels, rotation=45, ha='right')\n",
        "    ax.set_title(f'{cluster_names[cluster_id]}', size=14, y=1.25)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "df_train = pd.concat([X_train, y_train], axis=1)\n",
        "df_train.groupby(\"cluster\")[\"obito\"].mean()\n",
        "\n",
        "#Trainning with 10-fold cross validation\n",
        "for cluster in cluster_list:\n",
        "    data = df_train.loc[df_train['cluster'] == cluster]\n",
        "    X = data.drop(['obito', 'cluster'], axis=1)\n",
        "    y = data['obito'].fillna(0)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=43)\n",
        "\n",
        "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
        "        x_train, x_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        # XGBoost\n",
        "        xgb_model = xgb.XGBClassifier()\n",
        "        xgb_model.fit(x_train, y_train)\n",
        "        xgb_pred = xgb_model.predict_proba(x_test)[:, 1]\n",
        "        xgb_auc = roc_auc_score(y_test, xgb_pred)\n",
        "\n",
        "        # Random Forest\n",
        "        rf_model = RandomForestClassifier()\n",
        "        rf_model.fit(x_train, y_train)\n",
        "        rf_pred = rf_model.predict_proba(x_test)[:, 1]\n",
        "        rf_auc = roc_auc_score(y_test, rf_pred)\n",
        "\n",
        "        # CatBoost\n",
        "        cat_model = CatBoostClassifier(verbose=0)\n",
        "        cat_model.fit(x_train, y_train)\n",
        "        cat_pred = cat_model.predict_proba(x_test)[:, 1]\n",
        "        cat_auc = roc_auc_score(y_test, cat_pred)\n",
        "\n",
        "        # LightGBM\n",
        "        lgb_model = lgb.LGBMClassifier()\n",
        "        lgb_model.fit(x_train, y_train)\n",
        "        lgb_pred = lgb_model.predict_proba(x_test)[:, 1]\n",
        "        lgb_auc = roc_auc_score(y_test, lgb_pred)\n",
        "\n",
        "        # TabPFN\n",
        "        tab_model = TabPFNClassifier(device='cpu')\n",
        "        tab_model.fit(x_train, y_train)\n",
        "        tab_pred = tab_model.predict_proba(x_test)[:, 1]\n",
        "        tab_auc = roc_auc_score(y_test, tab_pred)\n",
        "\n",
        "        # AUCs\n",
        "        auc_scores = pd.concat([\n",
        "            auc_scores,\n",
        "            pd.DataFrame([{\n",
        "                'cluster': cluster,\n",
        "                'fold': fold,\n",
        "                'xgb': xgb_auc,\n",
        "                'rf': rf_auc,\n",
        "                'cat': cat_auc,\n",
        "                'lgb': lgb_auc,\n",
        "                'tab': tab_auc\n",
        "            }])\n",
        "        ], ignore_index=True)\n",
        "\n",
        "\n",
        "#Performance comparison graph\n",
        "data_means = []\n",
        "data_errors = []\n",
        "\n",
        "for cluster in range(0, 5):\n",
        "  data = df[df[\"cluster\"] == cluster]\n",
        "\n",
        "  list_means = []\n",
        "  mean_xgb = float(np.mean(data[\"xgb\"]))\n",
        "  mean_cat = float(np.mean(data[\"cat\"]))\n",
        "  mean_lgb = float(np.mean(data[\"lgb\"]))\n",
        "  mean_rf = float(np.mean(data[\"rf\"]))\n",
        "  mean_tab = float(np.mean(data[\"tab\"]))\n",
        "  list_means = [mean_xgb, mean_cat, mean_lgb, mean_rf, mean_tab]\n",
        "\n",
        "  data_means.append(list_means)\n",
        "\n",
        "  std_xgb = np.std(data[\"xgb\"])\n",
        "  std_cat = np.std(data[\"cat\"])\n",
        "  std_lgb = np.std(data[\"lgb\"])\n",
        "  std_rf = np.std(data[\"rf\"])\n",
        "  std_tab = np.std(data[\"tab\"])\n",
        "\n",
        "  erro_padrao_xgb = std_xgb / np.sqrt(len(data[\"xgb\"]))\n",
        "  erro_padrao_cat = std_cat / np.sqrt(len(data[\"cat\"]))\n",
        "  erro_padrao_lgb = std_lgb / np.sqrt(len(data[\"lgb\"]))\n",
        "  erro_padrao_rf = std_rf / np.sqrt(len(data[\"rf\"]))\n",
        "  erro_padrao_tab = std_tab / np.sqrt(len(data[\"tab\"]))\n",
        "\n",
        "  # degrees of freedom\n",
        "  g = 9\n",
        "\n",
        "  list_interval = []\n",
        "  xgb_interval = st.t.interval(confidence=0.95, df=g, loc=mean_xgb, scale=erro_padrao_xgb)\n",
        "  cat_interval = st.t.interval(confidence=0.95, df=g, loc=mean_cat, scale=erro_padrao_cat)\n",
        "  lgb_interval = st.t.interval(confidence=0.95, df=g, loc=mean_lgb, scale=erro_padrao_lgb)\n",
        "  rf_interval = st.t.interval(confidence=0.95, df=g, loc=mean_rf, scale=erro_padrao_rf)\n",
        "  tab_interval = st.t.interval(confidence=0.95, df=g, loc=mean_tab, scale=erro_padrao_tab)\n",
        "  print(tab_interval)\n",
        "\n",
        "  errors = [float(mean - low) for mean, low in zip(list_means, [xgb_interval[0], cat_interval[0], lgb_interval[0], rf_interval[0], tab_interval[0]])]\n",
        "\n",
        "  data_errors.append(errors)\n",
        "\n",
        "clusters = [\"Anaemia\",\"Young\", \"Immune Activation\", \"Reccovery\", \"Immunodeficient\"]\n",
        "alg = [\"XGBoost\", \"Random Forest\", \"Catboost\", \"LightGBM\", \"TabPFN\"]\n",
        "data = data_means\n",
        "\n",
        "data = np.array(data).T\n",
        "x = np.arange(len(alg))\n",
        "width = 0.13\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "ax.grid(axis=\"y\", linewidth=0.5, ls =\"--\")\n",
        "ax.set_axisbelow(True)\n",
        "\n",
        "colors = sns.color_palette(\"YlGnBu\")\n",
        "\n",
        "for i in range(len(alg)):\n",
        "    ax.bar(x + i*width - width*2, data[i], width, label=alg[i], color=colors[i], yerr=errors[i], capsize= 4, ecolor=colors[i+1])\n",
        "\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(clusters, rotation=0)\n",
        "ax.set_yticks(np.arange(0, 1.05, 0.05))\n",
        "ax.legend(loc='upper right')\n",
        "ax.set_ylim(0.5, 1.02)\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "bS34vAbDVOjF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}